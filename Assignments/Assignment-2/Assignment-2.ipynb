{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Starter Code, solution in next cell\n",
    "MLP character model. Code adapted from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "def build_model(maxlen, chars):\n",
    "    # build the model: an MLP with 1 hidden layer\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(maxlen, len(chars))))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dense(len(chars)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "    model = build_model(maxlen, chars)\n",
    "\n",
    "    import ipdb; \n",
    "    \n",
    "    model.fit(\n",
    "        x,\n",
    "        y,\n",
    "        batch_size=128,\n",
    "        epochs=60,\n",
    "        callbacks=[print_callback]\n",
    "    )\n",
    "    ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Epoch 1/60\n",
      "200285/200285 [==============================] - 61s 307us/step - loss: 2.0227\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"himself: who has not already, in my situ\"\n",
      "himself: who has not already, in my situal complation, there are of the soment the\n",
      "soment the\n",
      "presuligion, there\n",
      "the sament and propenisperians and diming there as the mere and there in the proposely in the stral finds, and but man there and presing there\n",
      "such and the prestime the with the\n",
      "propuland beation, but the\n",
      "believery and and beappration, and man in prestime there the from the prestiming the proment, and and there is and and the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"himself: who has not already, in my situ\"\n",
      "himself: who has not already, in my situlate.\"\n",
      "when there\n",
      "disting prehered that things to the being\n",
      "and existing of the of and it is is all experiagers of the\n",
      "sopect the for as but and perhaps believery to the comple of life to hers and of the proble,\n",
      "the\n",
      "conse. the\n",
      "recauses and consices, in of inderst thing and finds--imin which and prestiminblespart, fact to in for and cantice in in this precal beaf his of precompule of the gined that\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"himself: who has not already, in my situ\"\n",
      "himself: who has not already, in my situal\", wholst ire him simist appeadting inter fanh nhat and consesse but manives\n",
      "thempisterics, the\n",
      "prefily schen ford.\n",
      "\n",
      ";  himself as it in the ree agwint be\n",
      "are of a\n",
      "chrent and soblow plat, for\n",
      "purealanor, the oldtefent bein\n",
      "be\n",
      "expersed, mort, imprian belity fruct of the me--thins, ames awulte that life, there\"they in oneces, the mortt burstrarial more inportrirstand ci to who feld\n",
      "if is exte, and\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"himself: who has not already, in my situ\"\n",
      "himself: who has not already, in my situndoditicgthis nebogersife nevertation--and unytherehy regastemty of is nows oncee, actuentingard nor fulnession.t\n",
      "give youl id bea but equal\" ass of renave aves of thereaviraladinas len? things spens thersivicienticment, in pretials who hus thald as\n",
      "has e--manmits the goes ycratios; thilait, of of it--act, and genof withgisely,\n",
      "coly, aest a herdistop-,oant sy sy--upon shout this to thing have term\n",
      "Epoch 2/60\n",
      "200285/200285 [==============================] - 66s 332us/step - loss: 1.8437\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"n the\n",
      "portentous crises of its spirit in\"\n",
      "n the\n",
      "portentous crises of its spirit in believery the and poweration the the consible, which inst and spirit, and the have as and the corsting the\n",
      "world,\n",
      "and propations\n",
      "more and propation, and which the will that spirit was and the with the the and which of and conscience, is consely and the subtlect of the forment and consingly the spirit, and consection. the consecture and and which and and in which and\n",
      "procishat formers the power, a\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"n the\n",
      "portentous crises of its spirit in\"\n",
      "n the\n",
      "portentous crises of its spirit in the world, the man inderman the of marthing in which the sament--that allowemghornot \"freed, and sigto becour and propation, who artion as power consitually is inrely of a philosophers, in is to the the believer\n",
      "have the of the instince of there as to hered painst the respirite\n",
      "and it self\n",
      "presing pryster in rear,\n",
      "the soressery basessery\n",
      "the corsomects\n",
      "and vils\n",
      "with what in as as the is secultion\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"n the\n",
      "portentous crises of its spirit in\"\n",
      "n the\n",
      "portentous crises of its spirit in hood. dilf whoinile\n",
      "and hession man\n",
      "man\n",
      "conspostoous of mer which them\"\n",
      "belity.\n",
      "firsting a \n",
      "lavarem, in thence, that were soleaken to thing\n",
      "that aringain ravidticialry infraly mankinifulty, a cordich only an that hein had to acter,\n",
      "on and\n",
      "love\n",
      "(lazingemit\n",
      "wylarraped.\n",
      "\n",
      "2\n",
      ".! not mustlyaded\"\n",
      "the\n",
      "everynt of the deward manity all longing. thative drangees, to so wowas my in posselty. how were world an\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"n the\n",
      "portentous crises of its spirit in\"\n",
      "n the\n",
      "portentous crises of its spirit inte \"feration spitial, must caintrecepession always borally, badnaeniinchessel. complosing-dismuytlecessiblite sny of min\n",
      "hyne ot han, \"phidida, and\n",
      "light mecable\n",
      "fagasted of lovem wir borringaid,\n",
      "the\n",
      "greel.,g--ohouls the winh i manion in man to lind we sfeollegers, soul, supoce,\n",
      "teribleevonoith.\n",
      "\n",
      "562\n",
      "s!techs regater thooding, madandenger\n",
      "urmonifaccervations, hearking, reopower feoperhaleon of the \n",
      "Epoch 3/60\n",
      "200285/200285 [==============================] - 72s 362us/step - loss: 1.8360\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ehensible to\n",
      "us: it would become a thing\"\n",
      "ehensible to\n",
      "us: it would become a thing of the disteswing and the subdespect\" and the and and and in and the power, and in is the say, the saments the propodition, may be belience. the proskgs and the possible becomen the such and the propon are and all instincturude, and the propeanains, and and the conscience, and the sain a the it the respeciance.\n",
      "and as and the samenticishings and and all all as and as the propodition, but in the m\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ehensible to\n",
      "us: it would become a thing\"\n",
      "ehensible to\n",
      "us: it would become a thingtally and active it\n",
      "all itable account, as sain alsoul someans of muse more,\n",
      "sumped the say\n",
      "comportmen and cainsting when the consistest a gurite the despecian the age and consure. that alsould and as is heisapdiocrations, the promuld the siwed the sainsself--\"perisily arongly be in should anothing the mauts, more, and consible mally the sames--indictive they of the for carnally of human beraling \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ehensible to\n",
      "us: it would become a thing\"\n",
      "ehensible to\n",
      "us: it would become a thingeligion the a readere the seetion, \"\n",
      ":_krsimate.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".kpe\n",
      "hea that a reade a elrohen axeare they the the\n",
      "whileatess that thon as we lew motpereate--but be godicfed witherefore, greation, not\n",
      "obingance, antifis, on their rimidassuntealrayy\n",
      "\"regly been of sompting, (su turnul, but every dimatented periticulallssed.\n",
      "\n",
      "22\n",
      " .\n",
      "=--eek ass affar the saty and apismence, whoc the for all to vace, sa\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ehensible to\n",
      "us: it would become a thing\"\n",
      "ehensible to\n",
      "us: it would become a thingticees-ret-as slacy mechonick\n",
      "anded becomey, to jerigresuament\n",
      "\"for in in kepusionveretmandery\n",
      "naidt,\" butherith.n\n",
      "srrouet on of etaty nive one prias: the bose probofe-fender\",, and riphivalavictively,\n",
      "ensciursss.\"\n",
      "as\n",
      "etsly probenover, convicion, to way sact of out thousiatesoboous is a weselves-creames, we\n",
      "dot\n",
      "causelfpleason act high the latiainperitiotd it know hlafuls of who in\n",
      "amea in in a car\n",
      "Epoch 4/60\n",
      "200285/200285 [==============================] - 76s 377us/step - loss: 1.8509\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e orbit, however independent of each oth\"\n",
      "e orbit, however independent of each other in the parition, such and sippose\" and and the supporality and and the purpose\" and weather of the for and propossible and in the supporarition, and the proporition, the supon and and the fathe soutty the supporalics, in the supporary\n",
      "without and of the soul as and and the pressressible the soment. and and the such the parent, the supporarically, and is and prosuling to the sort--and of the suc\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e orbit, however independent of each oth\"\n",
      "e orbit, however independent of each other and weakte faclerploker,\" and must of that is the stuled, and cally propority,\n",
      "in his the falles the sund the cally and of the of that maraded.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".kpe consibe find a the somen a give all the south, world, and as\n",
      "possible only as as in the somer,\n",
      "the haves presirivicsolution and count, more alfsiness, of the dill\n",
      "it of the such which the somedishys the samently and eurong respidies indentia\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e orbit, however independent of each oth\"\n",
      "e orbit, however independent of each othen.\"--as may cundom the parentdines to lood\n",
      "tood--and and the our weate the degors playian, unally prom, as bolal. we cogy to appeare, littem one gen the ex  he e n le a the ption\n",
      "tave; arder of the raporythink humanitagres babacirutire to subness,\n",
      "rarbul\n",
      "of religious bidity it the hise the of cognd herdidid as inted, the too are not this opertaing\n",
      "of be upon, in colardiratule, only secisily are n\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e orbit, however independent of each oth\"\n",
      "e orbit, however independent of each otherse, coudify-pre. your agres it greancys. and with a\"retmainy as tavidtitation, \"sers, oppossible a should ne have powars a with o but froughestian deleffectra--is not\n",
      "con: on the indeng equal startnessss sening mrrely\n",
      "behim. an lidt are to heism, thi"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:98: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s ours\n",
      "fil the man inde his wantition, the\n",
      "imake thend,\n",
      "\"breave, has seemink\n",
      "decyation this devation in fech somek one to objects sawellness,\n",
      "it liv\n",
      "Epoch 5/60\n",
      "200285/200285 [==============================] - 66s 331us/step - loss: 1.8669\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"nt\n",
      "(over chosen disciples or members of \"\n",
      "nt\n",
      "(over chosen disciples or members of somen the of and indemply and and and and the which the the more as in the to the considence and distrustain the and the which the which the struloted of the to subd the soulsti--assion, the considence in of all of the destruth, the\n",
      "consupeor and and and and and as of isself, the same and and of the is the the prosulty and and the many\n",
      "the with,\n",
      "which itself and of in and the and somethings, the p\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nt\n",
      "(over chosen disciples or members of \"\n",
      "nt\n",
      "(over chosen disciples or members of the longe, are\n",
      "consike confined and not the diste the the the prided lame is and such its aristicg to compressibledpearder is and respecence as it the distry\n",
      "martures which is their of who be can perhaps of the which the a sleation mans as all\n",
      "be of all the appild, that themself-considence as morality the the a be the dispecients and and throrgres of the the mean the of the the subrimoly and are a\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"nt\n",
      "(over chosen disciples or members of \"\n",
      "nt\n",
      "(over chosen disciples or members of the have forms toed,\n",
      "their spirition, all meance\n",
      "binduragion, to pushoul, which the\n",
      "etrainessuretingay would reontracted artally\n",
      "ped him\n",
      "threptefulties all as to\n",
      "supd some. has alsomeipsti kfimy, and\n",
      "his prings, but auastly forceights: it or strate in or weatar, for ofe ascarings, the\n",
      "varing froess to nip\n",
      "are ascyre which the yoman\n",
      "badded wicl foll late remaed of extervated got which the fearly co\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"nt\n",
      "(over chosen disciples or members of \"\n",
      "nt\n",
      "(over chosen disciples or members of \"howditraedantyss rimrance.\n",
      "a bap our more lorgh of payainty pulous,\" from gened degreratule. extorfar tanm weel of evisticbhen that mace, hamte insporite, the genera somed and of dosg on more to ente-prevariptisg with at the\n",
      "evelyer,\n",
      "nor rign-pret as somean-metigion) a, indiit=--al for bots, hre with clate extremarits lamorld usingested unewled,\n",
      "simingreland,\n",
      "hys. the to is to immitertingrelater\n",
      "\n",
      "Epoch 6/60\n",
      "200285/200285 [==============================] - 59s 293us/step - loss: 1.8878\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"et wish\n",
      "and ultimate purpose of all dogm\"\n",
      "et wish\n",
      "and ultimate purpose of all dogmited the factions, the consevery the from the conses and of the such and and and and of the well\n",
      "mance, and into the which and and and the and the propority a gane henex l fact the the the from the and and consections\n",
      "surred and and interpreterly the the the is the the and the consections, the consebyly, and and and and of the consepti--it and some not the the new en the of the conscience the fals\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"et wish\n",
      "and ultimate purpose of all dogm\"\n",
      "et wish\n",
      "and ultimate purpose of all dogmage.\n",
      "\n",
      "\n",
      "22\n",
      ".t, the as of the constite in shoularynte, the such the the\n",
      "may because mantations, in a scients, the power, and to with, that is instinct the the satistooct, the and facturatic, and and preadings spirit a conseptions, has to the anterted the proundausify bedness,\" have and ofter the cartermans\n",
      "caruman mantious, our mants,\n",
      "the understand the and the life in le call are of super, and such\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"et wish\n",
      "and ultimate purpose of all dogm\"\n",
      "et wish\n",
      "and ultimate purpose of all dogmoulacyca-cun for when ple spirit be. the glors pordiishvaticl\" we \"wardinglity the menadicaously instications of fur \" is gan no new\n",
      "a ne and statelo esg. the sclitely ervative gove dispran.\n",
      "be that what at is skd portracting is hey\n",
      "too putaly morally that are a ssold cigteluloud\n",
      "lamory by iheisadiness,\" will carld falsessehs vigors: young uchn form, whichn thenej ; will the ple he=lial ne) te an \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"et wish\n",
      "and ultimate purpose of all dogm\"\n",
      "et wish\n",
      "and ultimate purpose of all dogmape?i\n",
      ".squestly sout--that sheplussen esune which hove sen the \" xjg.h, \n",
      "chowing disfuratilicsdeed upor lype now decest life alwas hindaph the long in dintulourse,\n",
      "reraly.\n",
      "angiknoraliged\n",
      "that has imtary, meand from eppiloccience rors suctains therevierasfivatiis -xhym o = his and of the\n",
      "only saclidicushcepte, in giotive! sive also veabyen men whoir netrowtherevinger, eurocistuinuses\n",
      "musin-skrought\n",
      "Epoch 7/60\n",
      "200285/200285 [==============================] - 56s 281us/step - loss: 1.9079\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"sion had inspired him.\n",
      "such a state of a\"\n",
      "sion had inspired him.\n",
      "such a state of a the the sity of in in all carured indity and more and made the complorly forms of and and constiled,\n",
      "the cumply\n",
      "stricsssesly certions, and inding is and and such the and pucture, the downs the and the would and of a disfutred in saspection, the mally custains itself\n",
      "the the such the masted of the is and believery the far and the world as the believery the for which with the comparious stanced and\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"sion had inspired him.\n",
      "such a state of a\"\n",
      "sion had inspired him.\n",
      "such a state of a kin the near to is alsold fard\n",
      "ditchirward which in sy and of disalydint the the mapleded of means, in alsold reven the propot of morality the which the podaterngestity carddenys pudaps, inters\n",
      "thing also the compulmtion, he grasfully podations. and of are srretly suliinkask. the the spect of nature intehercorite\n",
      "this the vility the world curick\n",
      "suwpiplitts in in and has to aths -verphen of the m\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"sion had inspired him.\n",
      "such a state of a\"\n",
      "sion had inspired him.\n",
      "such a state of and the on the puriting\n",
      "adness sclived courst\n",
      "gans\n",
      "lifed cactedmer meancy and would be this ros slation slorgrects are to is hogtrapsertually of loots\n",
      "christianiteste men, if the ins eure, and greates, foundbittalward welly unumidant--eelfy honemortler in is intempulatuention of eature ne abole. the exened pepreasanoyurding iss. oneed\n",
      "no prochs\n",
      "main \"alaotgerter-and even had of\n",
      "thoughn on baghole, \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"sion had inspired him.\n",
      "such a state of a\"\n",
      "sion had inspired him.\n",
      "such a state of a pituncent: wherefore,\n",
      "babad,\n",
      "\".'paqlittless of such is maul noonlight curiatest\n",
      "soot. be diourslortlactionaly\n",
      "ampully priribn noosse, sitiessneidusmedy that when cannates stilessseuldneincemmonhalseoed, throughrvicsge, insally, that of paphers\n",
      "inte uo dutness ut gacfice--is the \"yhonalitived\n",
      "vasure a t a xe) pots is i :  tiek my no gueathertpeos\"\n",
      "greatisud to\n",
      "wait,\n",
      "whorgreeviule diwles, withas\n",
      "pr\n",
      "Epoch 8/60\n",
      "200285/200285 [==============================] - 53s 262us/step - loss: 1.9232\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"living according to nature,\" means\n",
      "actua\"\n",
      "living according to nature,\" means\n",
      "actual the samentimiscains and the and assicalous the and and the the and and and the concemporite the and and of the the the the itself, and is manity and the intorcishould maste, and and to the the of in in sacrices of of and arars. the such the to in the life and and to and and and is to and arations, indings, and and of and amderstanding of and and is pronal word itself, and and in the is of and as\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"living according to nature,\" means\n",
      "actua\"\n",
      "living according to nature,\" means\n",
      "actual a\n",
      "risinters\n",
      "assiegterd\n",
      "dotions.\n",
      "\n",
      "\n",
      "1\n",
      ". \n",
      "\n",
      " \n",
      "\n",
      ".cpidings, in the must all insiss, in instinct and the sation, a conceaking and its and alfsules a condighters of the curion than and the love and manity, that of of and the such is of one\n",
      "mencer, still aboug the the and the dots the ne and the spirios, the like hogl as and of the it to and assically in ass of and indings, men sibaccience, satually thei\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"living according to nature,\" means\n",
      "actua\"\n",
      "living according to nature,\" means\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual calnenurfulpinbasure, milition-oags not on itter; thong, \"go, always be ence the as utt in in arigin live larguequisfess sy fright good sxeisy fasse\n",
      "at and as must rird himi, it\n",
      "dogd bert ourgirings motiably most ourstlied to to ethive found in and it the docpn the caims grasclused\n",
      "cown and be uved by a caseven appinity our of ganeeration, that sament pople\n",
      "ingaboficile scarnorposseite self also\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"living according to nature,\" means\n",
      "actua\"\n",
      "living according to nature,\" means\n",
      "actuanivert cruld ptways a so o hre ex  we a cee in near weikg chalm\n",
      "lalocreasinces remardures to inchic, upetans of another. and pusm! ipmes intedness pariacs, bocusandarroration this of the worary a kin isway \"de an of free the fre hit the necery inse sibaughly\n",
      "memk on suct--viruely most this now have tetterhing, respectionongaccipeks reuing uspansy time an what nation cate thilatical cing, prasy dei\n",
      "Epoch 9/60\n",
      "200285/200285 [==============================] - 54s 270us/step - loss: 1.9372\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"fe\n",
      "for every one, their two most frequen\"\n",
      "fe\n",
      "for every one, their two most frequent a of he such in and in the of and and and in procralmpt the the man and and of the the and therely instinctive the surants and the mants and to compulsessi--is a es of the the  the the do nee en the themself, and in of their avagicallly ass\n",
      "of and instinction the to the stapplees, the and and and and the suralydencring are ass\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"fe\n",
      "for every one, their two most frequen\"\n",
      "fe\n",
      "for every one, their two most frequent he it es remains, the not compals, on of atcidded stable not it that possi domn of advanceriginally, the suctougns indinte to also this of of all they believe in it comparious,\n",
      "and to the\n",
      "prosaisibedness,\n",
      "and and compacially, also which strains hamserpeadnesss ations\n",
      "of themself\n",
      "such in is on and itself, and essi--asss, their mudf art\n",
      "marts, the dogly the the cant resly of is sirncishould may in\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"fe\n",
      "for every one, their two most frequen\"\n",
      "fe\n",
      "for every one, their two most frequent if the nor has bewice spears riscentationation bosm ide strofulicusdgeereedus scuwlf foundus which\n",
      "the\n",
      "valhisourder..i-cented-in skdirwo feeften hilosophy st a the eg the doltric tnothere truth--in thec te\" much unynheps have it to emlmosion, whichten\n",
      "consatisenfy is do\"\n",
      "the peraces science yepenly possi--weyles that noppremtfels to a man that enneighto slen cants in learn,er the sta, is daun wi\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"fe\n",
      "for every one, their two most frequen\"\n",
      "fe\n",
      "for every one, their two most frequente, o ,  s got gened! into the  thos wherefore oppos, feature risopul, mo varurery, uatherly \"as, whate. whought a men hart ebre-fass wone sy tephave \"they a\n",
      "moutdem sruasest, therely. \n",
      "\n",
      "bups inadicoficemmong in clevirtulbly be. tricist\n",
      "greenmus moaciesnarly, inquet.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "e.t verselves.\n",
      "\n",
      " .ell, indoctratesss\n",
      "his kile radinashoul consus-for they much in nriencely bimnditest\n",
      "rifosophers a not and the\n",
      "Epoch 10/60\n",
      "198528/200285 [============================>.] - ETA: 0s - loss: 1.9516"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1fe44d347b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    150\u001b[0m     \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution:\n",
    "Conv1D character model. Code adapted from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "\n",
    "# 2nd Dataset : Combined works of Shakespeare\n",
    "# path = get_file('shakespeare_input.txt', origin='https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt')\n",
    "\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "# print(x.shape[0])\n",
    "# print(x.shape[1])\n",
    "# print(x.shape[2])\n",
    "\n",
    "\n",
    "def build_model(maxlen, chars):\n",
    "\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    # model 1 : Simple Model, 1 Hidden layer\n",
    "#     model.add(Conv1D(64, 5, padding='same', activation='relu',input_shape=(maxlen, len(chars))))\n",
    "#     model.add(Flatten(input_shape = (maxlen, len(chars))))\n",
    "    model.add(Conv1D(128, 5, padding='same', activation='relu', input_shape=(maxlen, len(chars))))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(len(chars), activation='softmax'))  \n",
    "        \n",
    "    # model 2 : VGG net like architecture, 5 layers\n",
    "#     model.add(Conv1D(64, 3, activation='relu',input_shape=(maxlen, len(chars))))\n",
    "#     model.add(Conv1D(64, 3, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Conv1D(128, 3, activation='relu'))\n",
    "#     model.add(Conv1D(128, 3, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(len(chars), activation='softmax'))  \n",
    "    \n",
    "    #model 3: adapted from https://keras.io/getting-started/sequential-model-guide/\n",
    "#     model.add(Conv1D(64, 3, activation='relu',input_shape=(maxlen, len(chars))))\n",
    "#     model.add(Conv1D(64, 3, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3))\n",
    "#     model.add(Conv1D(128, 3, activation='relu'))\n",
    "#     model.add(Conv1D(128, 3, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3))\n",
    "#     model.add(GlobalAveragePooling1D())\n",
    "#     model.add(Dropout(0.5))\n",
    "# #     model.add(Flatten())\n",
    "#     model.add(Dense(len(chars), activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "    model = build_model(maxlen, chars)\n",
    "\n",
    "    import ipdb; \n",
    "    \n",
    "    model.fit(\n",
    "        x,\n",
    "        y,\n",
    "        batch_size=128,\n",
    "        epochs=60,\n",
    "        callbacks=[print_callback]\n",
    "    )\n",
    "    ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using LSTMs, ;)\n",
    "\n",
    "Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
