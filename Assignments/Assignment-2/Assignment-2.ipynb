{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "Epoch 1/60\n",
      "200285/200285 [==============================] - 17s 85us/step - loss: 2.5459\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \", that he has\n",
      "acted in everything with m\"\n",
      ", that he has\n",
      "acted in everything with mes in o athise vid is thithe this dore phis phis perate, and med insily this chithis chithis aen of the and encof in is of the sumely an as and and an thithe an in the and al the menthe and ved hich many his sicheras and aus and ind in the as of as ale med an the s male s mal ad as in med ins an as and ans and amen mas mont of ill and mesthit mof in the as of as in the as ind is the\n",
      "desthis ches i\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \", that he has\n",
      "acted in everything with m\"\n",
      ", that he has\n",
      "acted in everything with med miny hathof ce alo ghe pesely his the dof and aumely; and iund at ouly is his de are\n",
      "at oo phis siere aly acithe forthist at of mh thiche s alides chithiss lo shis me this apself ale st\n",
      "le pores ins and this whichale s in the monol and mon mene singly men th is of ond as of\n",
      "his men of so meliss aad as are the co ale se andamely\n",
      "th his erally ape mid this as lfolsy and at\n",
      "ur and an mole ase dis \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \", that he has\n",
      "acted in everything with m\"\n",
      ", that he has\n",
      "acted in everything with merypmeho ow, hhelay in whis\n",
      "m: thaby of theostipe. alc aica siriod,\n",
      "-soneskth, hhincilfore domsimfod ilichen,\n",
      "ess mowt his porf sad yo mis s icullo and oup\n",
      "th be whic dise cas the, pos vertet, and,\n",
      "onsiminyly., werle fonishiledy deis\n",
      "agry,oghiessssoff tha selvod aderofstictucallist.\"\n",
      "\n",
      "an soflintery ts thor, shitcologe ssen,\n",
      "andofed lo mel fon thas nm mely-thiil ofores sat hy uivedis seous\n",
      "his whic\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \", that he has\n",
      "acted in everything with m\"\n",
      ", that he has\n",
      "acted in everything with mesins\n",
      "los\n",
      "obeorngef mayr rchtast eor allabsty-morlysys ther-ey as hmugliy.pe\n",
      "ry.--hewors chislighighidgfyoris\n",
      "wsinothoplypoesi stocor asd cletidear oang ammnsitevif o\n",
      "bly bo thus rothat for ccitt euthe falllasund ond ius lomp\n",
      "les phete- ho m aly atd fupulofy, whrtitiny,\n",
      "exblitto t ehme aut\n",
      "so y afruld, awe th gepermusisisrhis evary cesriny. ly teep os eemtret hoo puicinve tr thot. ino it.\n",
      " 5ty tha\n",
      "Epoch 2/60\n",
      "200285/200285 [==============================] - 17s 85us/step - loss: 2.4617\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ed unconsciously and accidentally. they \"\n",
      "ed unconsciously and accidentally. they wore the merin tin the munth\n",
      "\n",
      "forlentinte the\n",
      "\n",
      "mont the the knowher the ther ther the pure\n",
      "prouthe singhe\n",
      "rantrentithe cheverounthe shithe she\n",
      "mantere the\n",
      "murthe the ther the the mant re\n",
      "the mont of\n",
      "ron tre the masing tont ker that te furte thor ther\n",
      "that\n",
      "of ghe\n",
      "wherhe sonter forthe therethor ther\n",
      "merturery the\n",
      "soune there sher the mothe  forther the\n",
      "\n",
      "for the the whith the\n",
      "the hare the herthe that\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ed unconsciously and accidentally. they \"\n",
      "ed unconsciously and accidentally. they whin the mothar thin the the prerount\n",
      "st gheruthir thare ghan thered wed re the\n",
      "montha monke\n",
      "the\n",
      "gerer tore whing the thar thoust ermunt and\n",
      "grithe wored hiven ther thount ont he there bot\n",
      "\n",
      "aud ne whath sithous ther techure\n",
      "these sedingonthe stint of\n",
      "ure lfuthe the thow that of the\n",
      "ghorl wireny\n",
      "and grawtit theritho ghar the that\n",
      "\n",
      "aver uthe tion brerte\n",
      "thom. the te be the ture\n",
      "futhe sfouls of\n",
      "and i\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ed unconsciously and accidentally. they \"\n",
      "ed unconsciously and accidentally. they oomanis none rg dognenn\n",
      "ly\n",
      "cund asughe pociestre ter fuconthet ond ind herd\n",
      "dg\n",
      "ferd fartoumt hithe canferigran the\n",
      " titimy-ct manime as case s tha\n",
      "ghithas\n",
      "hlecanduno reditotrere,\n",
      "l5rextemer-therithionther lo\n",
      "d -romtre,\n",
      "chissutyas tachangsevant r thise fromsthengitstier, wiveroutse\n",
      "warn sa nithe boucha ce mughond and, ivelonthin\n",
      "s onthiouous.\n",
      "\n",
      "2a4 nofretidr: -th mesiantion, theesthong\n",
      "\n",
      "fhe\n",
      "cndiund \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ed unconsciously and accidentally. they \"\n",
      "ed unconsciously and accidentally. they shamgenid my hanellim\n",
      "aaf\n",
      "lermanexrityfend s, the thever perthrunemessing\n",
      "int\n",
      "on inghenrpeevare-sdority tuat lr in mthicksrl4st, kondiverin- a whad and\n",
      "arastrod; an of manlthephimment thil thenolithe faly\n",
      "turuntlry. than iom\n",
      ".owly. werqueny heryyllrectede noneitr,\n",
      "te phisksentot bulumer,\n",
      "choruthecedrinools- formits ermt the\n",
      "gheperucn sicall itpoop.\n",
      "btir blec roust fueucarl bot,\n",
      "lu thauduqued w mas\n",
      "Epoch 3/60\n",
      "200285/200285 [==============================] - 17s 84us/step - loss: 2.4423\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" is bound to some such indiscreet billy-\"\n",
      " is bound to some such indiscreet billy-perere pore man fomes for of the pand and mont wor the fore wanco the wore ion re the to the tome tod fople to mot expere to the whace te the the tore the to the the fore the fope pore fome io the for the to for the tored fon the tore tome fore to the tommean to the ther the sompees po tobe to luthe for the tome fore to the the tope to be to to to lo the to f the the for the to le poule fo to the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" is bound to some such indiscreet billy-\"\n",
      " is bound to some such indiscreet billy-peroed pasplescof and tall ase tore hame to thecovely atle too sore the fot on the propreserporet on thamerero tor fol tha thay to the pod wof re tor the the tome to the were tod  toumbee tod pore to the ce tomal tod to they to \"gace to the f oustion wor to mone to the the tome the too got \" the we the fon the po sero go the tome for poreseto the tomerece for tome to the mpe foume. t to le the ore\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" is bound to some such indiscreet billy-\"\n",
      " is bound to some such indiscreet billy-penescest thecolssenitd, tores, anweritangicl\" tom ros torm no tortye of lo d timtie fon tis, os derto lusleque to  nverieg ter al det; at pord porouber gat tt ita ofal ty, tike tho gutin? the wonl que ene fore pryseo) peopisoog inman agit ato ag tha songareby, ats am te add ys ichita mpanitrereo, anque e os tog\n",
      "perele wa\n",
      "drot on th n the d make to the kempnesta tor alm, wit of rmejevery af dace d\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" is bound to some such indiscreet billy-\"\n",
      " is bound to some such indiscreet billy--andingus bjeit ec sf conte onnt nistlo\n",
      "the wor m them ns hta justeve \n",
      "b olamily. the hery bolo que tto ghatior he lo\n",
      "pemptioto and wure becm ta \"whike wata dung pormain thel of aneat tak os theverall -t \n",
      "anl sas ig ao  tte bel tas, isw latel ng ataly iongell, thapercanon ys fum\"nilr foctescole t, jurysase 'r the if carabe tap oo an\"gros at eamweas yst fonoveriegiano woalassan d\n",
      "oust msa lomume ta\n",
      "Epoch 4/60\n",
      "200285/200285 [==============================] - 17s 87us/step - loss: 2.4359\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ition, without which the\n",
      "expression itse\"\n",
      "ition, without which the\n",
      "expression itse fure the f amenthit illerathe themperis the the thes at the here the themesthe the hers as muth the remuthe the hers ate the the hamuthe the hemurthe them the he he here here the the theresthe thethe\n",
      "the the heres and the hers ast he hemerthe the there the serthe the here here the the the hams hat the the the the hers hat the sterthe\n",
      "the hestertument the hampelfer him the reat at as the hestere i\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ition, without which the\n",
      "expression itse\"\n",
      "ition, without which the\n",
      "expression itse furend the furkent alleke fre ther athe tamte the heruat the hs ablenthe reat at ale the the or onethe the enthe\n",
      "hthe them-ato hto the hemull of the hame ar ass ches the the\n",
      "on the in tue the re the the ehs the thame the the chats at the sem the thes humentule the\n",
      "s\n",
      "chimathe  hemule denthe cherewilles averutheer aitionthithe hemallatowthat alleatthe of thes at onr aiveluthe the hertere thamest in\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ition, without which the\n",
      "expression itse\"\n",
      "ition, without which the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expression itsenat ao here ofllaks timatry mhilltof thether usterming cems er\n",
      "juct oe cawe co temptempente. at ure the hher sumalf treeramse frs ifstive ing aimols (whe be burino  ; el? gever aus ones uhlor th esmune tha thei inis of the whem thmure thes act bulkeme aed\n",
      "mathereledentinol, iad on hheply ef therst hhe vir hafor. the wore hamasithet ableaition,\n",
      "amporeercumanwestablingrmuther ferentirkenf.--thisod, \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ition, without which the\n",
      "expression itse\"\n",
      "ition, without which the\n",
      "expression itseiadl mebline, ondurouf l(tek of thr ahs, alr chumrmas resod meraukent, the\n",
      "what a bemprrald\n",
      "cel awo iha belcremple spertfenedve, in shamurthe  ofmuntefimmevery-dof ogr -he mulkerw\n",
      "ans dree: tingin thedregezaty anepuvesso-ithilur futh upcass.ays arbe ce hal as turelomeea i ss af, astthece,\"bud.\" iess wheatag  phamos meot ta thewhwin at aris\n",
      "sunt atine ofylesans cherilf revelf roulf all asts biekvog\n",
      "Epoch 5/60\n",
      "200285/200285 [==============================] - 17s 84us/step - loss: 2.4305\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"n what may be understood as one's\n",
      "advant\"\n",
      "n what may be understood as one's\n",
      "advanthe of res the s of the re che is and the prestion the mpresthe the the ster the the the men ment ment and the mes le fore the the preatin the the the ha che it men mathe the the mane the the man the the mune mentithe the ghe man the mas the man the the ho mes on the the the the the che man the the the the che the the the the the the the the the the the the che the the the the the the che the the t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"n what may be understood as one's\n",
      "advant\"\n",
      "n what may be understood as one's\n",
      "advant whe hen se fill becomey, chos the ry the sees the terd the the ghas the; the mer the the mous the he re freminct en thes rom tion the preceste tho ghos; the rel the s mprelits of chitge this ce pre fulle en whe ing tof en moral yo ver the there the preit rom the thitg the mal the the che the men the tho ghe mas the the excense conding tha man the the cheris int etr chese mant and pretite tho hmat\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"n what may be understood as one's\n",
      "advant\"\n",
      "n what may be understood as one's\n",
      "advant\n",
      "an ticll as in arthit  of rleycan a d theg derifrot tolll te--ane tin th mpllis a ns me tseure s baonght ing hemond fiesilstrloweul\n",
      "ose be reverd meys ind wooh --wher  who thee cermes blofery, whel anpre of mandly, rabroneves in and romenalitnithha, to, thas ocaspsestowascinsthes thendevery uns apios thas thaiptheytione,--thas by the mesicnien uth pancesspty, co re\n",
      "ahed ubthe the s ofrititho gran\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"n what may be understood as one's\n",
      "advant\"\n",
      "n what may be understood as one's\n",
      "advanthe ces bieas thent resster it is st--phe\n",
      "the, trethis stubly oncerits ghomini nt theourot ef anmante thes ryt wo hp paspen--it ra. inn\n",
      "misncublda sertisy.\"-athiew\n",
      "onato thanc ong haibllfore theullosion\n",
      "prellymeismany! dnugresithowe houl of isn wthex an? ehe  hithe need lpeaco nd buan es itos_;s--thacw acco!tho  pa bmin thal thegrueldonoto- wh eracissiend, whal cat fored na meveid otores tha wmal s\n",
      "Epoch 6/60\n",
      "200285/200285 [==============================] - 16s 81us/step - loss: 2.4254\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \".\" so reasoned mankind at one time, and \"\n",
      ".\" so reasoned mankind at one time, and to se thes and tod ther as the thes and thing the st the fis thing this the stoul mane the stous thith thes the there them ther thing tom the\n",
      "samune them and sely and toment his the stous this the stalithe\n",
      "soment and the maling the sall toong them ancalion,\n",
      "and thithe toreand theresthe toull the theresting and the thaling tong thit them.\n",
      "the son thy as the st of thit cand tof the there thing the t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \".\" so reasoned mankind at one time, and \"\n",
      ".\" so reasoned mankind at one time, and withe and the vically bo mores and and at the there hes blingoun s the mand the moner than monest toat and he thes mare talite ar them.\n",
      "ing toull merere\n",
      "fraling songlized and and ssorest an thas the in themante then thing this tore\n",
      "fare ment al te trem. ton thisgol and more fingre thithithit ol the  thepresthe s rous fol andis the at mon ther ats lofis te the fally\n",
      "in sones the tural ta the solly \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \".\" so reasoned mankind at one time, and \"\n",
      ".\" so reasoned mankind at one time, and ro eve toren the\n",
      "sedeitond ang taligot  haplareding thes toringungro th artin thigat: thate ingrinoly thitimstise that\n",
      "chardenis strrughtem ansutr ankill andy thelllict and blinit ch ianlotedis sonedothe asding\n",
      "ghithil seemyoun--hol ad inos of d\" aving calispthe s on thend\n",
      "phest theprrstte oust afd at ancertel: thaprielsoton safornts es thur-dis  of\n",
      "elpertoung, ind andelousign,\" wadlfyit pulld\"mad\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \".\" so reasoned mankind at one time, and \"\n",
      ".\" so reasoned mankind at one time, and estuy p inad te ssef--ly sop of buritp ina ped ruits--thsmon prys inghand--womlizod. scord atsdopiris shistintess-entitestoudsmunoumsthall ofeppicturiss my in ofwisece tsem no st.\"--apen. thecirrishisg topr tio tare ofdeliom; ald hitheve tor hardichatrraggonis\n",
      "caceuct it eof wirel blectome!\"--t ciemond srmanze ounty, buacl of in s\"--pols\n",
      "itsulongitnd thines, us thaplyhianion, an tuman more aruslly\n",
      "Epoch 7/60\n",
      "200285/200285 [==============================] - 17s 87us/step - loss: 2.4243\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"t is regarded as the\n",
      "only thing that can\"\n",
      "t is regarded as the\n",
      "only thing that cand mont of il the ghim the core the rovery and inge be the roule to ghis doperatn the har cament inger tor marid this anderot er the ros, ing of mere tore fore the firment\n",
      "or mantiry, and comand the for ther ange fore the hamer ing of coprehe noughe so ghamperithas\n",
      " hamere nf ore have the hor mand more for ham, the har he hore ther cher ange no the\n",
      "\n",
      "114\n",
      "\n",
      "=here dary porian ixperfent of hare than the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"t is regarded as the\n",
      "only thing that can\"\n",
      "t is regarded as the\n",
      "only thing that cand there nor if the thol whangho s\n",
      "perpe nomplen sol the be the hare ther beed be or bed and thore der porsisto th ingerer orcesed ing of copernand thar the hames, formath thomesnat soprecomon ththere salf thencempanar the for ing ore ther an ther and\n",
      "mange the indernot bat an the thexcepinnos of ar the\n",
      "ramprof ste thom, her andand do marin the vered on the or mare rathe fore har arexceprato of are\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"t is regarded as the\n",
      "only thing that can\"\n",
      "t is regarded as the\n",
      "only thing that candexcepinnongid tho jexat theredmenithe \"f aroimandiritegha; fore iompelfoe has  thes tor bat existsef exayninale's ore ither acomesom erimithis dewmoca whichalm nt whace hare it--phrerempey sore pits\n",
      "latcerath\n",
      "r thar, rowisthot, ther arsenors ig ikn ile ger\n",
      "all in is foment chess. th iamser thity keng tore the t ithast, thare mpersobly ngerequatger\n",
      "ofermpongo, isaly tooramant o gorwe haprobins io \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"t is regarded as the\n",
      "only thing that can\"\n",
      "t is regarded as the\n",
      "only thing that cand moverolaws ch ploism pofitenuthe ahyimans, for dngere dowerlownoquinly co wh rovepin\n",
      "an ecruter goo thepry,: \"tot malo wa th muthat shacian monverand\n",
      "mance pbefwsol' inspithe sal'sreen, th thiigh. , cespther, arriacd asby ef counce they sof whork nokered commswl: whouriond hs or mats bod arcisid\n",
      "-hoves an ercarcorpith he evag ramerlt icind, as io\n",
      "doufre hor the g wh\" opeshiny o d\n",
      "toquihby,\n",
      "hom h\n",
      "Epoch 8/60\n",
      "200285/200285 [==============================] - 17s 83us/step - loss: 2.4239\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"t does not require deliberation. as soon\"\n",
      "t does not require deliberation. as soon the gon well on be no men as the his se s an the baco se f an eren the gro in mon the s an ches and it an the so s in ble who  he mat on th is an or an the wall ch s an ing or an in an as an so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s an whin the chas an f of the s an fin the bat he mon tho s an the pacho t al an on be on whing ion an on the be no serf che f an the ghe sons is an on ar an is ble in s an an the s an of an  he mang the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"t does not require deliberation. as soon\"\n",
      "t does not require deliberation. as soon the go at en the\n",
      "men or fot in been co silf and rers al se fereelo d se foching on mas in\n",
      "\n",
      "f co the s of the s an in all on ha derigro for the an thos the whil  he ha phes and an on geres tho g of the beco fer in pionos ing ang at ches io bat of mon  hangitho es in ses ace be meres in whe he se fer me pras an s of mant in sals an\n",
      "beleso thit an chon thon the profist he we he for thin ther and sil\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"t does not require deliberation. as soon\"\n",
      "t does not require deliberation. as soon chow mas amer rod fove to geo\n",
      "s f if noldon nhtincasise\n",
      "fes pr eos of ofsctin sof en isre, one ss s btit ces micho woch aquele wave\n",
      "wanchiero annextite, obeermesed lo so feri grte tha shimpseos aribli giog exervin\n",
      "o an for bles comerly. the sis tredicl oravo te ros sunteroligilngrousir cat ans is\n",
      "ely al, sperlobicn thon thomithe hir  aonco se foce tora ce st oes the fel mein p\n",
      "iso bie te ins io f\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"t does not require deliberation. as soon\"\n",
      "t does not require deliberation. as soonvelles\n",
      "phis phito lint, chy upho religns ee po toseghinis ld ao seriacs au tol  no wat\n",
      "o this tod no wom he ss,\n",
      "u woad to thosese chon ut an salithire ste de mith pangioutt ko a oo shu bein os celluga ritis ss, ion mpch\"mas ees\n",
      "on\n",
      "ciontisince\n",
      "feldsored ; thod inpertipas o bo he\" wion don urt futho m e\n",
      "then tassit--isino:  he tho wos alo\n",
      "ned iranc chorhe, ail qulel, tha's hseiver alo\n",
      "gan bion, and \n",
      "Epoch 9/60\n",
      "200285/200285 [==============================] - 18s 88us/step - loss: 2.4259\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" individuality.\n",
      "\n",
      "\n",
      "95\n",
      "\n",
      "=ethic of the deve\"\n",
      " individuality.\n",
      "\n",
      "\n",
      "95\n",
      "\n",
      "=ethic of the deved an=--do withery ires ofor thered atity andict of omed, as and werchesery his of and nof chit in sere the sorese\n",
      "songere the se whe s of chere sery why he\n",
      "sedity of int and ind rodesting is whid thes whof rof the red the fure nof the stery af the\n",
      "serery: whe whil the desther ondede, and the fores lf onderery the so which werer he f red wion the the se wher the s which of are dey of\n",
      "res which mery\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" individuality.\n",
      "\n",
      "\n",
      "95\n",
      "\n",
      "=ethic of the deve\"\n",
      " individuality.\n",
      "\n",
      "\n",
      "95\n",
      "\n",
      "=ethic of the deved an=--as and doved in the so the why here of ond trodescars antse for is which mong the ser aalurs,\n",
      "in iveny he hes wald wore iny he delits ero\n",
      "sowhin wheld athe s ing if ame to which the he dire wher the s whes whind tored toveryed thes thes ef therenser the phesesery he ss of ure\n",
      "why his an we chequedy onof inged, sof no whos harsery co toperystity ty hiss are sored iny raty ar whice the the he\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" individuality.\n",
      "\n",
      "\n",
      "95\n",
      "\n",
      "=ethic of the deve\"\n",
      " individuality.\n",
      "\n",
      "\n",
      "95\n",
      "\n",
      "=ethic of the devedede=--dieton, hy tie\n",
      "sododiond, aved acteera--touady, aterytof iris yuad\n",
      "oferid oust, iver werthos, hoo nime at teed kson an mare,\n",
      "diviincca; ase onde no hope faymserold inndese,\n",
      "ro monits, divesthe hiro\n",
      "therraly urthity, f rotevy to icollay on, are burtate citledede, ave thes wheon\n",
      "dimperanty he stintang sof, minglicod unstrandedenfof therecauntity nebot of them, as nce torontys toes\n",
      "of chere--t\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" individuality.\n",
      "\n",
      "\n",
      "95\n",
      "\n",
      "=ethic of the deve\"\n",
      " individuality.\n",
      "\n",
      "\n",
      "95\n",
      "\n",
      "=ethic of the deveond beod taithedf ameus, fareom, ood no, eved rimpilct, toprid wpllerdev beat t\" wescratlsteund oty nwelle,-ehquisedarto whacresf nif\n",
      "lofir titteisedutsedw.\n",
      "so pesict he mrreded: \"noulral no arif--be lasti, ersmegrieva roncaupe pwriltion)eros sea by meysiatity t: hudilxcenteang owatrdt), ion toreolr--ar\n",
      " nalbarizy willretgile ss tho kir deesod, illerce, bearth tand, ave gredras vy uoncaurtso the\n",
      "m\n",
      "Epoch 10/60\n",
      "200285/200285 [==============================] - 16s 82us/step - loss: 2.4211\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"nation of nature.=[5]--metaphysic reads \"\n",
      "nation of nature.=[5]--metaphysic reads done f anditton. which\n",
      "there them no bee mall ata phine of ace fouthe oreat on the furtith if the fure fore\n",
      "fore severy and of the fure the fithe sore tore\n",
      "ponderithe for his of the poreeroughis the\n",
      "furthes which of pherense porsict of chets ion the goreat oullostion sorelof in the of reragsines\n",
      "aplistof the phither hices apeistound of the foret of antien and of ond pourit of all got of oul to the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nation of nature.=[5]--metaphysic reads \"\n",
      "nation of nature.=[5]--metaphysic reads dom hin which oughith ch se ppeion and atien, whichits if the sters if thith ivery the sotig ian the ber\n",
      "ak of and and co the beery, iof oun beemen\n",
      "\n",
      "f phis\n",
      "bacemy cins \"f achems in \" ouligneta pinithe ferend blistsous fferingit ingion as of encencand ixcertatin tirt if ith if the ster all ghithe\n",
      "reloferen apprithous of the forenery, so ager, and the sheres pertidities ing themenound at atthe ghore\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"nation of nature.=[5]--metaphysic reads \"\n",
      "nation of nature.=[5]--metaphysic reads deby phenephasisa dit thy madlsty, at andtithing ins thice prerimpiatie hf of th har baides thas thet whecerofos\n",
      "bundty allty of huhe af er ncsilf chemand indentounge fot hegne, wwith selunepraleditutive ghop iofis sovaly a diectued ho phiple she\n",
      " mith ife f enchst ente ofe cotf imes iat ou batoe to furet\n",
      "ere if\n",
      "limune \"fabe avelympeata \"fathal \"wirlacpnichome\n",
      "\"erthethy whach, thiems ce tonitlat i\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"nation of nature.=[5]--metaphysic reads \"\n",
      "nation of nature.=[5]--metaphysic reads dem hplisyict, ser,\n",
      "s houstores will an hy orbacleags, os \"whice\n",
      "aite tamwill d, amis whigatel, sowist ecous\n",
      "dverdity ntimely, foulegn, if shthice, chtispichicolsubs\" bat ouag bet kun freaveryicism, aubida\n",
      "scaulwey wsstid, ahe e plo, paive con enty cila--whs\n",
      "aftmonk o semplisestaicisemadiniince fodsely mion pt ixtabercamiebatous baccanly,o ene hily\n",
      "mith im ly imen. ate tion wici morillfato -omith \n",
      "Epoch 11/60\n",
      "200285/200285 [==============================] - 17s 85us/step - loss: 2.4190\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" better. the delight in common, the\n",
      "plea\"\n",
      " better. the delight in common, the\n",
      "pleat on the peston the sestithit the hes ins mos in s in whaling in thing thit iop ins anithithis the thithespensespondensthe thes mithis the sesthe thelespess io thes soplits an thesperits ios the poingit ive se the pous it whithe stiel, mone sof thithis instion deverely, the has an thes at in the cesthit ins ions for the phithes. hit chimesef the stin thit his mof the s ithe shis the itse foull sit\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" better. the delight in common, the\n",
      "plea\"\n",
      " better. the delight in common, the\n",
      "pleat on the prealiogs, thes mones ofor the sio the thit ins incalf thes the pestos mos the phithit the meselis of the sporitis thed ige te thither thithe fimesto the thes its oforense thit ans this fore this is the hesse fore fonce tiendess chessesseno bean whithe that nes the the hims has in thithele ithe shithisperithithiss bo moned it what he thes its mos thes tho acestopinstithe pewhalw the chase\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" better. the delight in common, the\n",
      "plea\"\n",
      " better. the delight in common, the\n",
      "pleat doumit wos mo dcans have ye forthit on the nats at how\n",
      "selutho ceds moy dipecen thigle soo lownins therimrs,\n",
      "grobleso in chufis aw. the muane is be dres toit  tuens ave--pous\n",
      "\n",
      "s kines so theo. tie sedienst ipicens we puras?\n",
      "wer hese--ho whal. te, butheud, apw the mire fowerd ani\n",
      "tovt, ho enfotald,\n",
      "bour hitien. whithe ce fereis fovenitr of ch thiople. mones thus if loptoongs, an stolly. is theven\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" better. the delight in common, the\n",
      "plea\"\n",
      " better. the delight in common, the\n",
      "pleasumeac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moficapenithivedupapars, ife mmeerompos fftremons chictianc, mo nawheen the arivisulo ) esimin. \n",
      "\n",
      "arlupties, the afeer eeffeed bekin weverios thit peliopulintwm, ofthaangutraashait sspuntoki; thas of endensscur belels eovin thaspsivelobyonlthith\"lhace shithecenadivica ce the reos\n",
      "or hare morag do cerancounmosasils, aan\n",
      "hareva be hod hes thorigh, en beerpatly, fhe hor bet iblousrycons, bedde\n",
      "Epoch 12/60\n",
      "200285/200285 [==============================] - 18s 89us/step - loss: 2.4263\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"yspeptics like what\n",
      "is convenient, so th\"\n",
      "yspeptics like what\n",
      "is convenient, so the stel and mone the bele ment ef reste the\n",
      "belist, the mast the sto the the belles monem ant\n",
      "\n",
      "hally, and anlleges ant ous mas inle sos las bee\n",
      "mest--be the be bes morell to mare the sempresiby beente se bet ored romestint and mathe steveredis the mant of the stee\n",
      "the make wist us monk of verelt experted and mand ins as the ste tave the stever, the sallets of the stee be the sall toul the\n",
      "salt ant \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"yspeptics like what\n",
      "is convenient, so th\"\n",
      "yspeptics like what\n",
      "is convenient, so the in thang at andesses, the ham inly tove\n",
      "beine mang datis at wall the lome last--the\n",
      "sere tis all ge se s brenes roke blederestall be\n",
      "the\n",
      "cascould anthes whall sous belles ing aindallestel beal calleest one laslest,\n",
      "belists listallet. bel belly the kend all all to mas mont rast oned rotall ablenges ant of ome\n",
      "s whis the sallekend atlesteed, th ther belt en allagling ane llegot ant ment matus and \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"yspeptics like what\n",
      "is convenient, so th\"\n",
      "yspeptics like what\n",
      "is convenient, so tho soce tout ing histud fus oul amo at\n",
      "ex ctsougnes orse nalty hat ally of\n",
      "ave . iout  or\n",
      "monith urllew ag aat eake inveronog, su tho hes--eh rim ry int lxadpereinatly anithastone, south whemeas nd mlake t\n",
      "buak  oukid caskind elligkee, ne--ras ofeko dl bibsele ti g wark ntaed resestiwe and\n",
      "ghis moor\n",
      "baof--mok \"freis at at ce wn chsoot wes coveis att tel gant oht oas un nde\n",
      "oubidney nela bed ualt\n",
      "in\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"yspeptics like what\n",
      "is convenient, so th\"\n",
      "yspeptics like what\n",
      "is convenient, so thas tha ate keranellots--whag\n",
      "\n",
      "he wiondply anginverly co be judgrede daclico vinjuslest\n",
      "at bhe the mans tilt\n",
      "lofrvat? hha dale tusthese--gparuble dnll\" nupllirthopedraysa,\n",
      "lf ih sestotad s aplesterthace ves atino\n",
      "sveg e antho es, bsee pnol dale bonghta do: min?\n",
      "dedm nisike\n",
      "ce somed. ce sisl west on isk owe  s wiik\n",
      "asle ctarecosmed, mon takin\n",
      "to sonam atlagrigasstas indirothao sto thon thiaglest. lo\n",
      "Epoch 13/60\n",
      "200285/200285 [==============================] - 18s 88us/step - loss: 2.4244\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"g very much about it, simply because its\"\n",
      "g very much about it, simply because its\n",
      "ins ind anderaly the caprecouthe ther and them and thererecond and ater as\n",
      "mact as in wher and the raty the comenand ther wither and\n",
      "endiverougher and the wher ther whom nat ther and\n",
      "serabe ther as and and plopecronger as pher the\n",
      "sof the s at ther wher and ther and there whom ther whal ather whol whinger and\n",
      "romperse whil theres wher and comerever is whicher angreres the them somering the s wher\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"g very much about it, simply because its\"\n",
      "g very much about it, simply because itsene. in ing\n",
      "roferesencopreas an atr aing wall ther opresind\n",
      "wher whor ther wer gow ther ingeres at must es whald be warid\n",
      " sare thati nommerthe sa pheresagnd ther mod\n",
      "frelleging, ther on exispis ond serpathen ther\n",
      "whor whan tren wher atrer whor gherecogr watiny whather ars tondurby whangrowhe\n",
      "sond whothers wheromechaveryongrelingither,\n",
      "whil ther mas nor gopechessind ator ther meramedusinn whorgeth\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"g very much about it, simply because its\"\n",
      "g very much about it, simply because itsince saciin\n",
      ",\n",
      "activerys noe cn them nowencins ef te matring\n",
      "ces llgica wiscenty the such,\n",
      "werling atd halg, whthaveryus nhug onver!onin caratry non thethes, at\n",
      "ustonpthee.\n",
      "[2] ure ficliycen, been corering mo\n",
      "tlefurin iucens wherwiof lood fond orcaic\n",
      "mas ess going fon ys endeling inn,\n",
      "whel asoulf vor whind h menot erandeclutinglend on\" p: werit inn ecopthis whorred the\n",
      "cestre an,\n",
      "whill cousldorpboe\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"g very much about it, simply because its\"\n",
      "g very much about it, simply because its saveeally,m nextr isomoulyif, nseat; ore hersor\n",
      "muthy belthaigr,\n",
      "wh ther\" noprevon\"inatled iomintirfedsand fone crijuscevet thirg toomprevont reomens\n",
      "forter ne1 cimrueviriof owothdes.\"wl aasers whes domt af teore\n",
      "sewis bratuplly bong esedigirsiag llvaven, hrevory th thel thkino ongerneraty\n",
      "cerevemy ansios wian ensredermingosde.  ah adere.\n",
      "\n",
      "on thesicbeno med iomes, loperfous nf cher\n",
      "ad on srem--th\n",
      "Epoch 14/60\n",
      "139776/200285 [===================>..........] - ETA: 5s - loss: 2.4114"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bab913efc32e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    115\u001b[0m     \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "MLP character model. Code adapted from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "def build_model(maxlen, chars):\n",
    "    # build the model: an MLP with 1 hidden layer\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(maxlen, len(chars))))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dense(len(chars)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "    model = build_model(maxlen, chars)\n",
    "\n",
    "    import ipdb; \n",
    "    \n",
    "    model.fit(\n",
    "        x,\n",
    "        y,\n",
    "        batch_size=128,\n",
    "        epochs=60,\n",
    "        callbacks=[print_callback]\n",
    "    )\n",
    "    ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "(None, 38, 64)\n",
      "Epoch 1/60\n",
      "200285/200285 [==============================] - 61s 305us/step - loss: 3.0354\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ges. many acts are called bad\n",
      "that are o\"\n",
      "ges. many acts are called bad\n",
      "that are o \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ges. many acts are called bad\n",
      "that are o\"\n",
      "ges. many acts are called bad\n",
      "that are ot\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ges. many acts are called bad\n",
      "that are o\"\n",
      "ges. many acts are called bad\n",
      "that are o \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ges. many acts are called bad\n",
      "that are o\"\n",
      "ges. many acts are called bad\n",
      "that are ou\n",
      "Epoch 2/60\n",
      "200285/200285 [==============================] - 61s 303us/step - loss: 3.0209\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"gris from a higher inclination--whoever \"\n",
      "gris from a higher inclination--whoever e\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"gris from a higher inclination--whoever \"\n",
      "gris from a higher inclination--whoever  \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"gris from a higher inclination--whoever \"\n",
      "gris from a higher inclination--whoever s\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"gris from a higher inclination--whoever \"\n",
      "gris from a higher inclination--whoever n\n",
      "Epoch 3/60\n",
      "200285/200285 [==============================] - 54s 268us/step - loss: 3.0246\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \". the\n",
      "question is, how far an opinion is\"\n",
      ". the\n",
      "question is, how far an opinion is \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \". the\n",
      "question is, how far an opinion is\"\n",
      ". the\n",
      "question is, how far an opinion ise\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \". the\n",
      "question is, how far an opinion is\"\n",
      ". the\n",
      "question is, how far an opinion isn\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \". the\n",
      "question is, how far an opinion is\"\n",
      ". the\n",
      "question is, how far an opinion isr\n",
      "Epoch 4/60\n",
      "200285/200285 [==============================] - 54s 272us/step - loss: 3.0258\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"us anxiety is felt that\n",
      "everything be do\"\n",
      "us anxiety is felt that\n",
      "everything be do \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"us anxiety is felt that\n",
      "everything be do\"\n",
      "us anxiety is felt that\n",
      "everything be do \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"us anxiety is felt that\n",
      "everything be do\"\n",
      "us anxiety is felt that\n",
      "everything be do \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"us anxiety is felt that\n",
      "everything be do\"\n",
      "us anxiety is felt that\n",
      "everything be doo\n",
      "Epoch 5/60\n",
      "200285/200285 [==============================] - 62s 311us/step - loss: 3.0263\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \", as betrayed, as discovered; he will pr\"\n",
      ", as betrayed, as discovered; he will pr \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \", as betrayed, as discovered; he will pr\"\n",
      ", as betrayed, as discovered; he will pr \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \", as betrayed, as discovered; he will pr\"\n",
      ", as betrayed, as discovered; he will pr-\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \", as betrayed, as discovered; he will pr\"\n",
      ", as betrayed, as discovered; he will prr\n",
      "Epoch 6/60\n",
      "200285/200285 [==============================] - 55s 276us/step - loss: 3.0265\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"whole ruthlessness of his own dear\n",
      "self:\"\n",
      "whole ruthlessness of his own dear\n",
      "self: \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"whole ruthlessness of his own dear\n",
      "self:\"\n",
      "whole ruthlessness of his own dear\n",
      "self:e\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"whole ruthlessness of his own dear\n",
      "self:\"\n",
      "whole ruthlessness of his own dear\n",
      "self:n\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"whole ruthlessness of his own dear\n",
      "self:\"\n",
      "whole ruthlessness of his own dear\n",
      "self:g\n",
      "Epoch 7/60\n",
      "200285/200285 [==============================] - 56s 280us/step - loss: 3.0265\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"t\n",
      "of the supremacy of aristocratic value\"\n",
      "t\n",
      "of the supremacy of aristocratic value \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"t\n",
      "of the supremacy of aristocratic value\"\n",
      "t\n",
      "of the supremacy of aristocratic valuee\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"t\n",
      "of the supremacy of aristocratic value\"\n",
      "t\n",
      "of the supremacy of aristocratic value \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"t\n",
      "of the supremacy of aristocratic value\"\n",
      "t\n",
      "of the supremacy of aristocratic valuea\n",
      "Epoch 8/60\n",
      "200285/200285 [==============================] - 90s 451us/step - loss: 3.0267\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ble. the distorted and diseased\n",
      "in his o\"\n",
      "ble. the distorted and diseased\n",
      "in his o \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ble. the distorted and diseased\n",
      "in his o\"\n",
      "ble. the distorted and diseased\n",
      "in his oa\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ble. the distorted and diseased\n",
      "in his o\"\n",
      "ble. the distorted and diseased\n",
      "in his o \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ble. the distorted and diseased\n",
      "in his o\"\n",
      "ble. the distorted and diseased\n",
      "in his ol\n",
      "Epoch 9/60\n",
      "200285/200285 [==============================] - 94s 468us/step - loss: 3.0265\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" are, in schopenhauer's\n",
      "phrase \"impossib\"\n",
      " are, in schopenhauer's\n",
      "phrase \"impossib \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" are, in schopenhauer's\n",
      "phrase \"impossib\"\n",
      " are, in schopenhauer's\n",
      "phrase \"impossib \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" are, in schopenhauer's\n",
      "phrase \"impossib\"\n",
      " are, in schopenhauer's\n",
      "phrase \"impossibr\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" are, in schopenhauer's\n",
      "phrase \"impossib\"\n",
      " are, in schopenhauer's\n",
      "phrase \"impossibo\n",
      "Epoch 10/60\n",
      "200285/200285 [==============================] - 99s 493us/step - loss: 3.0268\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"nderstood much, and was versed in many t\"\n",
      "nderstood much, and was versed in many t \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nderstood much, and was versed in many t\"\n",
      "nderstood much, and was versed in many t \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"nderstood much, and was versed in many t\"\n",
      "nderstood much, and was versed in many ti\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"nderstood much, and was versed in many t\"\n",
      "nderstood much, and was versed in many ts\n",
      "Epoch 11/60\n",
      "200285/200285 [==============================] - 105s 523us/step - loss: 3.0276\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"oil for one's own salvation. it would be\"\n",
      "oil for one's own salvation. it would be \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"oil for one's own salvation. it would be\"\n",
      "oil for one's own salvation. it would be \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"oil for one's own salvation. it would be\"\n",
      "oil for one's own salvation. it would bew\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"oil for one's own salvation. it would be\"\n",
      "oil for one's own salvation. it would bea\n",
      "Epoch 12/60\n",
      "200285/200285 [==============================] - 98s 488us/step - loss: 3.0273\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" they saw but the counterpart as\n",
      "in a mi\"\n",
      " they saw but the counterpart as\n",
      "in a mi \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" they saw but the counterpart as\n",
      "in a mi\"\n",
      " they saw but the counterpart as\n",
      "in a mie\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" they saw but the counterpart as\n",
      "in a mi\"\n",
      " they saw but the counterpart as\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in a mit\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" they saw but the counterpart as\n",
      "in a mi\"\n",
      " they saw but the counterpart as\n",
      "in a mi \n",
      "Epoch 13/60\n",
      "200285/200285 [==============================] - 98s 490us/step - loss: 3.0271\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" seems to him to be as unalterable as hi\"\n",
      " seems to him to be as unalterable as hi \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" seems to him to be as unalterable as hi\"\n",
      " seems to him to be as unalterable as hin\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" seems to him to be as unalterable as hi\"\n",
      " seems to him to be as unalterable as hid\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" seems to him to be as unalterable as hi\"\n",
      " seems to him to be as unalterable as hi,\n",
      "Epoch 14/60\n",
      "200285/200285 [==============================] - 96s 477us/step - loss: 3.0270\n",
      "\n",
      "----- Generating text after Epoch: 13\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rance\n",
      "of napoleon. there are words of go\"\n",
      "rance\n",
      "of napoleon. there are words of go \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rance\n",
      "of napoleon. there are words of go\"\n",
      "rance\n",
      "of napoleon. there are words of go \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rance\n",
      "of napoleon. there are words of go\"\n",
      "rance\n",
      "of napoleon. there are words of gor\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"rance\n",
      "of napoleon. there are words of go\"\n",
      "rance\n",
      "of napoleon. there are words of go\n",
      "\n",
      "Epoch 15/60\n",
      "200285/200285 [==============================] - 92s 461us/step - loss: 3.0267\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"lief in the senses, it is regarded as mo\"\n",
      "lief in the senses, it is regarded as mo \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"lief in the senses, it is regarded as mo\"\n",
      "lief in the senses, it is regarded as mo \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"lief in the senses, it is regarded as mo\"\n",
      "lief in the senses, it is regarded as mo \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"lief in the senses, it is regarded as mo\"\n",
      "lief in the senses, it is regarded as mos\n",
      "Epoch 16/60\n",
      "200285/200285 [==============================] - 94s 467us/step - loss: 3.0268\n",
      "\n",
      "----- Generating text after Epoch: 15\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"sagreeable or contemptible: and if he is\"\n",
      "sagreeable or contemptible: and if he is \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"sagreeable or contemptible: and if he is\"\n",
      "sagreeable or contemptible: and if he isn\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"sagreeable or contemptible: and if he is\"\n",
      "sagreeable or contemptible: and if he isi\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"sagreeable or contemptible: and if he is\"\n",
      "sagreeable or contemptible: and if he iss\n",
      "Epoch 17/60\n",
      "200285/200285 [==============================] - 90s 449us/step - loss: 3.0265\n",
      "\n",
      "----- Generating text after Epoch: 16\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"the knowledge that another suffers on\n",
      "ou\"\n",
      "the knowledge that another suffers on\n",
      "ou \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"the knowledge that another suffers on\n",
      "ou\"\n",
      "the knowledge that another suffers on\n",
      "oua\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"the knowledge that another suffers on\n",
      "ou\"\n",
      "the knowledge that another suffers on\n",
      "ouy\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"the knowledge that another suffers on\n",
      "ou\"\n",
      "the knowledge that another suffers on\n",
      "oum\n",
      "Epoch 18/60\n",
      "119424/200285 [================>.............] - ETA: 43s - loss: 3.0271"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7ae36fa058a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    136\u001b[0m     \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Conv1D character model. Code adapted from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "# print(x.shape[0])\n",
    "# print(x.shape[1])\n",
    "# print(x.shape[2])\n",
    "\n",
    "\n",
    "def build_model(maxlen, chars):\n",
    "    # build the model: an MLP with 1 hidden layer\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    \n",
    "#     model.add(Flatten(input_shape=(maxlen, len(chars))))\n",
    "#     model.add(Dense(128))\n",
    "#     model.add(Dense(len(chars)))\n",
    "#     model.add(Activation('softmax'))\n",
    "    # CNN model\n",
    "    \n",
    "    model.add(Conv1D(64, 3, activation='relu',input_shape=(maxlen, len(chars))))\n",
    "    model.add(Conv1D(64, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    print(model.layers[0].output_shape)\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "\n",
    "#     model.add(Flatten(input_shape=(maxlen, len(chars))))\n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(len(chars), activation='softmax'))    \n",
    "    \n",
    "\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(1):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "    model = build_model(maxlen, chars)\n",
    "\n",
    "    import ipdb; \n",
    "    \n",
    "    model.fit(\n",
    "        x,\n",
    "        y,\n",
    "        batch_size=128,\n",
    "        epochs=60,\n",
    "        callbacks=[print_callback]\n",
    "    )\n",
    "    ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 6s 0us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n",
      "Build model...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 143s 6ms/step - loss: 0.4045 - acc: 0.8008 - val_loss: 0.3029 - val_acc: 0.8696\n",
      "Epoch 2/2\n",
      "20384/25000 [=======================>......] - ETA: 23s - loss: 0.2302 - acc: 0.9068"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9d135ed4bebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
