{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import numpy as np\n",
    "import math\n",
    "from math import exp\n",
    "\n",
    "def actF(x):\n",
    "    act = math.tanh(x)\n",
    "    return [act,1-act*act]\n",
    "\n",
    "def cross_entropy_loss(output, target):\n",
    "    return (output - target)\n",
    "\n",
    "def preprocess(filename):\n",
    "    file = open(filename,'r')\n",
    "    dataset = [line.split() for line in file]\n",
    "    train_data = [np.array([float(row[0]),float(row[1])]) for row in dataset]\n",
    "    train_labels = np.zeros((len(train_data),2))\n",
    "    labels = [int(row[2]) for row in dataset]\n",
    "    for i in range(len(labels)):\n",
    "            train_labels[i][labels[i]] = 1    \n",
    "    return train_data, train_labels\n",
    "\n",
    "def softmax_norm(output_vec):\n",
    "    l = [exp(x) for x in output_vec]\n",
    "    npl = np.array(l)\n",
    "    mysum = npl.sum()\n",
    "    Dr = np.array([mysum for i in range(0,len(output_vec))])\n",
    "    return (npl/Dr)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        init_weights = [[random() for x in range(n_input+1)] for i in range(n_hidden)]\n",
    "        init_weights = np.array(init_weights)\n",
    "        self.hidden_layer = {'W':init_weights}\n",
    "        init_weights = [[random() for x in range(n_hidden+1)] for i in range(n_output)]\n",
    "        init_weights = np.array(init_weights)\n",
    "        self.output_layer = {'W' : init_weights}\n",
    "        self.layers = 2\n",
    "        \n",
    "    def forward_prop(self, input_vector):\n",
    "        inputs = np.append(input_vector,1)\n",
    "        w_mat = nn.hidden_layer['W']\n",
    "        prod = np.matmul(w_mat.reshape(3,4).transpose(),inputs.reshape(3,1))\n",
    "        act = []\n",
    "        delta = []\n",
    "        for i in prod:\n",
    "            act.append(actF(i)[0])\n",
    "            delta.append(actF(i)[1])\n",
    "        nn.hidden_layer['delta'] = np.array(delta)\n",
    "        new_inputs = act\n",
    "        new_inputs = np.append(new_inputs,1)\n",
    "        w_mat = nn.output_layer['W']\n",
    "        prod = np.matmul(w_mat.reshape(5,2).transpose(),new_inputs.reshape(5,1))\n",
    "        act = []\n",
    "        delta = []\n",
    "        for i in prod:\n",
    "            act.append(actF(i)[0])\n",
    "            delta.append(actF(i)[1])\n",
    "        nn.output_layer['delta'] = np.array(delta)\n",
    "        return act\n",
    "    \n",
    "    def backward_prop(self, loss): \n",
    "        loss = loss.reshape(2,1)\n",
    "        error_grad = [a*b for a,b in zip(loss,nn.output_layer['delta'])]\n",
    "        learning_rate = 0.5\n",
    "        error_grad = np.array(error_grad).reshape(2,1)\n",
    "        nn.output_layer['W'] = nn.output_layer['W'] - learning_rate*error_grad\n",
    "        \n",
    "        error_grad1 = nn.hidden_layer['delta'].reshape(4,1) * error_grad.sum()\n",
    "        nn.hidden_layer['W'] = nn.hidden_layer['W'] - learning_rate* error_grad1\n",
    "      \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_data, train_labels = preprocess('dataset.txt')\n",
    "    sum_error=0\n",
    "    row_count=0\n",
    "    epochs = 100\n",
    "    nn = NeuralNetwork(2,4,2)\n",
    "    for epoch in range(epochs):\n",
    "        row_count=0\n",
    "        sum_error =0\n",
    "        for row in train_data:\n",
    "            error = []\n",
    "            output = nn.forward_prop(row)\n",
    "            output = softmax_norm(output)\n",
    "            loss = cross_entropy_loss(train_labels[row_count], output)\n",
    "            if row_count <=1:\n",
    "#                 print(str(row[0]) + \" \" + str(row[1]) + \" \" + str(output[0]) + str(output[1])+ str(loss))\n",
    "                nn.backward_prop(loss)\n",
    "                sum_error += sum([(train_labels[row_count] - output)**2 for i in range(len(output))])\n",
    "                row_count+= 1\n",
    "#         print(\"sum:\",sum_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
